{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6134df17-2458-4d62-a174-32c9eb8cadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as n\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torchvision import datasets,transforms,models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4709d0d3-5908-444e-a0f4-4fb34ca9a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a data structre to manipulate Raw Data file\n",
    "\n",
    "class RawData:\n",
    "\n",
    "    def __init__(self, name='' ):\n",
    "        self.name = name      \n",
    "        \n",
    "        \n",
    "        \n",
    "    def convert_mat_tocsv(self):\n",
    "\n",
    "        mat = scipy.io.loadmat(self.name +'.mat')\n",
    "        \n",
    "        for i in mat:\n",
    "            if '__' not in i and 'readme' not in i:\n",
    "                 np.savetxt((self.name+\".csv\"), mat[i],delimiter=',')\n",
    "                    \n",
    "                    \n",
    "    def read_data(self): \n",
    "        \n",
    "        data = pd.read_csv(self.name+'.csv',\n",
    "                  names=[\"Time_stamp(s)\", \"AC_Power(W)\", \"SOC(%)\", \"DC_Voltage(volt)\",\\\n",
    "                        \"DC_Current(A)\", \"Temperature(°C)\"])\n",
    "        return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1962128c-145e-42c9-9b8b-0cebcf767f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_C10 = RawData('DataExpRaw_C10hW')\n",
    "data_C25 = RawData('DataExpRaw_C25hW')\n",
    "data_C50 = RawData('DataExpRaw_C50hW')\n",
    "data_C75 = RawData('DataExpRaw_C75hW')\n",
    "data_C100 = RawData('DataExpRaw_C100hW')\n",
    "data_D10 = RawData('DataExpRaw_D10hW')\n",
    "data_D25 = RawData('DataExpRaw_D25hW')\n",
    "data_D50 = RawData('DataExpRaw_D50hW')\n",
    "data_D75 = RawData('DataExpRaw_D75hW')\n",
    "data_D100 = RawData('DataExpRaw_D100hW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71482ef-697c-403b-989e-556eafdc4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C10 = data_C10.read_data()\n",
    "df_C25 = data_C25.read_data()\n",
    "df_C100 = data_C100.read_data()\n",
    "df_C50= data_C50.read_data()\n",
    "df_C75= data_C75.read_data()\n",
    "df_D10 = data_D10.read_data()\n",
    "df_D25 = data_D25.read_data()\n",
    "df_D100 = data_D100.read_data()\n",
    "df_D50= data_D50.read_data()\n",
    "df_D75= data_D75.read_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728ba8ce-c3a1-464a-b405-cdc542bea303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.0 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.3.0\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: gym in /opt/conda/lib/python3.9/site-packages (0.26.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.9/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.9/site-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym) (3.8.0)\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: keras-rl2 in /opt/conda/lib/python3.9/site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.9/site-packages (from keras-rl2) (2.6.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (3.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (5.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.15.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (0.15.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (2.6.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.46.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (3.20.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow->keras-rl2) (1.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (62.3.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2.1.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2022.5.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2.0.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0\n",
    "!pip install gym\n",
    "!pip install keras\n",
    "!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77bec7be-ed95-4d26-aea9-11a8e2246e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import gym \n",
    "from collections import deque \n",
    "import itertools \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random \n",
    "from gym import Env \n",
    "from gym.spaces import Discrete, Box, Dict, Tuple , MultiBinary, MultiDiscrete\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38214837-d390-4fc1-87e2-bff1b6ac11fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_stamp(s)</th>\n",
       "      <th>SOC(%)</th>\n",
       "      <th>DC_Voltage(volt)</th>\n",
       "      <th>DC_Current(A)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275013.839088</td>\n",
       "      <td>80.0</td>\n",
       "      <td>57.099998</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275014.801144</td>\n",
       "      <td>80.0</td>\n",
       "      <td>57.099998</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275015.781199</td>\n",
       "      <td>80.0</td>\n",
       "      <td>57.099998</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275016.913264</td>\n",
       "      <td>80.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275017.889320</td>\n",
       "      <td>80.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80420</th>\n",
       "      <td>358774.049899</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.099998</td>\n",
       "      <td>54.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80421</th>\n",
       "      <td>358775.061956</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.099998</td>\n",
       "      <td>54.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80422</th>\n",
       "      <td>358776.033012</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.099998</td>\n",
       "      <td>54.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80423</th>\n",
       "      <td>358778.562157</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.099998</td>\n",
       "      <td>53.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80424</th>\n",
       "      <td>358779.532212</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.099998</td>\n",
       "      <td>53.799999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80425 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time_stamp(s)  SOC(%)  DC_Voltage(volt)  DC_Current(A)\n",
       "0      275013.839088    80.0         57.099998      48.500000\n",
       "1      275014.801144    80.0         57.099998      48.500000\n",
       "2      275015.781199    80.0         57.099998      48.500000\n",
       "3      275016.913264    80.0         57.000000      48.500000\n",
       "4      275017.889320    80.0         57.000000      48.500000\n",
       "...              ...     ...               ...            ...\n",
       "80420  358774.049899    20.0         50.099998      54.599998\n",
       "80421  358775.061956    20.0         50.099998      54.700001\n",
       "80422  358776.033012    20.0         50.099998      54.700001\n",
       "80423  358778.562157    20.0         50.099998      53.799999\n",
       "80424  358779.532212    20.0         50.099998      53.799999\n",
       "\n",
       "[80425 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the data \n",
    "test_data= df_D25\n",
    "P=25*1000\n",
    "testData = test_data.drop(['AC_Power(W)', 'Temperature(°C)'], axis=1)\n",
    "testData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01efbafb-d2ad-43eb-8b99-6508bbe98420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constant parameters\n",
    "R= 8.314\n",
    "F= 96486\n",
    "z=1\n",
    "#T= 23\n",
    "T= 295.15  #K  (constant value )\n",
    "NCell= 40\n",
    "ILoss= 10 #A\n",
    "U0 = 1.375 #V\n",
    "Ri=0.00075  # mohm\n",
    "CStor= 8700000 #As\n",
    "#CStor= 2417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791b3fc8-e3e3-47a8-86de-584a02dfcd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.integrate import odeint\n",
    "from sympy.interactive import printing \n",
    "printing.init_printing(use_latex=True) \n",
    "from sympy import *\n",
    "import sympy as sp \n",
    "import math\n",
    "\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8a3d78-84a8-4734-8d16-9b6687146bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the initial guesses and the power cycle \n",
    "SoC = (testData.iloc[0].tolist()[1])/ 100  # expressed as a fraction\n",
    "U = testData.iloc[0].tolist()[2]\n",
    "I = testData.iloc[0].tolist()[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9a2e4b-cf66-4f28-afab-40bf3b1375e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "delta_t = 1  # seconds\n",
    "\n",
    "duration = testData.shape[0]\n",
    "#duration = 1000\n",
    "\n",
    "# Define a function to compute the power loss\n",
    "def compute_Ploss(U, I):\n",
    "    return U * I - P\n",
    "\n",
    "# Define a function to compute the voltage U(I) using the bisection method\n",
    "def compute_U_I(I):\n",
    "    def f(U):\n",
    "        return U * I - 1\n",
    "    a = -10\n",
    "    b = 10\n",
    "    tol = 1e-6\n",
    "    while b - a > tol:\n",
    "        c = (a + b) / 2\n",
    "        if f(c) == 0:\n",
    "            return c\n",
    "        elif f(a) * f(c) < 0:\n",
    "            b = c\n",
    "        else:\n",
    "            a = c\n",
    "    return (a + b) / 2\n",
    "\n",
    "# Define lists to store the values of SoC, I, and U over time\n",
    "SoC_list = []\n",
    "I_list = []\n",
    "U_list = []\n",
    "\n",
    "# Initial guesses\n",
    "SoC = testData.iloc[0].tolist()[1]  # expressed as a fraction\n",
    "U= testData.iloc[0].tolist()[2]\n",
    "I = testData.iloc[0].tolist()[3]\n",
    "\n",
    "# Perform the simulation\n",
    "for t in range(0, duration + delta_t, delta_t):\n",
    "    # Update the current I\n",
    "    I = I - delta_t * (-(I + ILoss)) / CStor\n",
    "\n",
    "    # Compute the voltage U(I)\n",
    "    U_I = compute_U_I(I)\n",
    "\n",
    "    # Compute the voltage U\n",
    "    U = NCell * U0 + ((NCell * R * T) / (z * F)) * math.log10(SoC**2 / (1 - SoC)**2) - NCell * I * Ri\n",
    "\n",
    "    # Compute the power loss\n",
    "    Ploss = compute_Ploss(U_I, I)\n",
    "\n",
    "    # Update the state of charge SoC\n",
    "    \n",
    "    new_SoC = SoC  + delta_t * (-(I + ILoss)) / CStor\n",
    "    \n",
    "  \n",
    "    if new_SoC  >= 0.8:\n",
    "        SoC = 0.8\n",
    "    elif new_SoC <= 0.2:\n",
    "        SoC = 0.2\n",
    "    else:\n",
    "        SoC = new_SoC\n",
    "\n",
    "    # Append the new values to the lists\n",
    "    SoC_list.append(SoC * 100)\n",
    "    I_list.append(I)\n",
    "    U_list.append(U)\n",
    "    \n",
    "#SoC_list=  SoC_list[::-1]\n",
    "#I_list = I_list[::-1]\n",
    "#U_list = U_list[::-1]\n",
    "\n",
    "        \n",
    "\n",
    "Sim_df = pd.DataFrame(list(zip(SoC_list, U_list, I_list)), columns=['SoC(%)', 'Voltage(v)', 'Current(A)'])\n",
    "#print(Sim_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04021d7-338e-41b8-9981-f7a228bf6efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SoC(%)</th>\n",
       "      <th>Voltage(v)</th>\n",
       "      <th>Current(A)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>53.556115</td>\n",
       "      <td>48.500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.999328</td>\n",
       "      <td>54.769949</td>\n",
       "      <td>48.500013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.998655</td>\n",
       "      <td>54.769912</td>\n",
       "      <td>48.500020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.997983</td>\n",
       "      <td>54.769875</td>\n",
       "      <td>48.500027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.997310</td>\n",
       "      <td>54.769837</td>\n",
       "      <td>48.500034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80421</th>\n",
       "      <td>25.673095</td>\n",
       "      <td>52.589425</td>\n",
       "      <td>49.043276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80422</th>\n",
       "      <td>25.672416</td>\n",
       "      <td>52.589393</td>\n",
       "      <td>49.043283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80423</th>\n",
       "      <td>25.671737</td>\n",
       "      <td>52.589362</td>\n",
       "      <td>49.043289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80424</th>\n",
       "      <td>25.671059</td>\n",
       "      <td>52.589330</td>\n",
       "      <td>49.043296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80425</th>\n",
       "      <td>25.670380</td>\n",
       "      <td>52.589298</td>\n",
       "      <td>49.043303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80426 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SoC(%)  Voltage(v)  Current(A)\n",
       "0      80.000000   53.556115   48.500007\n",
       "1      79.999328   54.769949   48.500013\n",
       "2      79.998655   54.769912   48.500020\n",
       "3      79.997983   54.769875   48.500027\n",
       "4      79.997310   54.769837   48.500034\n",
       "...          ...         ...         ...\n",
       "80421  25.673095   52.589425   49.043276\n",
       "80422  25.672416   52.589393   49.043283\n",
       "80423  25.671737   52.589362   49.043289\n",
       "80424  25.671059   52.589330   49.043296\n",
       "80425  25.670380   52.589298   49.043303\n",
       "\n",
       "[80426 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac9c9dff-98a0-49dd-9124-1dded04f92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9705983c-f2d3-49cb-b3d1-7d1f02d65dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = testData[:].to_numpy()\n",
    "Sim_DataFrame = Sim_df[0:testData.shape[0]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed0ff84-ff63-48da-82a3-1f10e115bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatteryEnv(Env): \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #define the action space\n",
    "        self.action_space= Discrete(3) \n",
    "        #define the observation space\n",
    "        self.observation_space= Box(low=np.min(DataFrame), high=np.max(DataFrame), shape=(DataFrame.shape[0],DataFrame.shape[1]), dtype=np.float32)\n",
    "        self.current = 1\n",
    "        self.P= 25*1000\n",
    "        self.R=  8.314\n",
    "        self.F=  96486\n",
    "        self.T=  295.15\n",
    "        self.z= 1\n",
    "        self.NCell = 40\n",
    "        self.length=60\n",
    "        #define the specific parameters \n",
    "        #represents the episode length \n",
    "        self.ILoss= 10 #A\n",
    "        self.U0 = 1.375 #V\n",
    "        self.Ri= 0.00075 # ohm\n",
    "        self.CStor= 8700000 #As \n",
    "        \n",
    "        self.SoC0= DataFrame[0][1]/ 100 \n",
    "        self.I0= DataFrame[0][3]\n",
    "        self.U_0= DataFrame[0][2]\n",
    "        \n",
    "     \n",
    "        def get_raw_state(current):\n",
    "            sample_array = self.observation_space.sample()\n",
    "            sample_array[:] = DataFrame\n",
    "            row = sample_array[current]\n",
    "            state = torch.tensor(row, dtype=torch.float32)\n",
    "            return state\n",
    "        \n",
    "        def get_sim_state(current):\n",
    "          \n",
    "            row = Sim_DataFrame[current]\n",
    "            state = torch.tensor(row, dtype=torch.float32)\n",
    "            return state\n",
    "        \n",
    "        \n",
    "        self.raw_state = get_raw_state(self.current)\n",
    "        self.sim_state = get_sim_state(self.current)\n",
    "        \n",
    "        self.Error=  abs(self.raw_state[1]- self.sim_state[0])+ abs(self.raw_state[2]- self.sim_state[1]) + abs(self.raw_state[3]- self.sim_state[2])\n",
    "        self.parameters= torch.tensor([self.ILoss,  self.U0,  self.Ri, self.CStor, self.Error], dtype=torch.float32) \n",
    "\n",
    "        #define initial state \n",
    "        self.state= torch.cat((self.raw_state , self.sim_state, self.parameters),0)\n",
    "\n",
    "\n",
    "    def step (self, action): \n",
    "        \n",
    "        def battery_simulation(ILoss, U0, Ri, CStor, SoC0, I0, U_0, P):\n",
    "            SoC = SoC0/100\n",
    "            I = I0\n",
    "            U =  U_0\n",
    "            P= self.P \n",
    "            \n",
    "            \n",
    "            duration = DataFrame.shape[0]\n",
    "            delta_t = 1  # seconds\n",
    " \n",
    "            def compute_Ploss(U, I):\n",
    "                 return U * I - P \n",
    "\n",
    "            def compute_U_I(I):\n",
    "                def f(U):\n",
    "                    return U * I - 1\n",
    "                a = -10\n",
    "                b = 10\n",
    "                tol = 1e-6\n",
    "                while b - a > tol:\n",
    "                    c = (a + b) / 2\n",
    "                    if f(c) == 0:\n",
    "                         return c\n",
    "                    elif f(a) * f(c) < 0:\n",
    "                        b = c\n",
    "                    else:\n",
    "                        a = c\n",
    "                        return (a + b) / 2\n",
    "\n",
    "            SoC_list = []\n",
    "            I_list = []\n",
    "            U_list = []\n",
    "\n",
    "            \n",
    "            for t in range(0, duration + delta_t, delta_t):\n",
    "                I = I - delta_t * (-(I + self.ILoss) )/ self.CStor\n",
    "\n",
    "                U_I = compute_U_I(I)\n",
    "\n",
    "                U = self.NCell * self.U0 + ((self.NCell * self.R * self.T) / (self.z * self.F)) * math.log10(SoC**2 / (1 - SoC)**2) - self.NCell * I * Ri\n",
    "\n",
    "                Ploss = compute_Ploss(U_I, I)\n",
    "\n",
    "                new_SoC = SoC + delta_t * (-(I + self.ILoss)) / self.CStor\n",
    "\n",
    "                if new_SoC >= 0.8: \n",
    "                     SoC = 0.8\n",
    "                elif new_SoC <= 0.2 : \n",
    "                     SoC=0.2\n",
    "                else:\n",
    "                     SoC = new_SoC\n",
    "\n",
    "                SoC_list.append(SoC*100)\n",
    "                I_list.append(I)\n",
    "                U_list.append(U)\n",
    "                \n",
    "            #SoC_list=  SoC_list[::-1]\n",
    "            #I_list = I_list[::-1]\n",
    "            #U_list = U_list[::-1]\n",
    "        \n",
    "            Sim_df = pd.DataFrame(list(zip(SoC_list,U_list, I_list)), columns=['SoC(%)','Voltage(v)', 'Current(A)'])\n",
    "            transition_df = Sim_df[0:DataFrame.shape[0]].to_numpy()\n",
    "\n",
    "            return  transition_df\n",
    "        \n",
    "        \n",
    "        #Increase specific parameters \n",
    "        if action == 1 : \n",
    "            self.ILoss += 0.005\n",
    "            self.U0 += 0.005\n",
    "            self.Ri += 0.005\n",
    "            self.CStor += 50\n",
    "            \n",
    "\n",
    "        #decrease specific parameters \n",
    "        elif action == 2 : \n",
    "            self.ILoss -= 0.005\n",
    "            self.U0 -=  0.005\n",
    "            self.Ri -=  0.005\n",
    "            self.CStor -= 50\n",
    "\n",
    "        #Maintain specific parameters \n",
    "        else : \n",
    "            self.ILoss += action \n",
    "            self.U0 += action\n",
    "            self.Ri += action\n",
    "            self.CStor += action\n",
    "         \n",
    "        self.parameters= torch.tensor([self.ILoss,  self.U0,  self.Ri, self.CStor, self.Error], dtype=torch.float32) \n",
    "        info={self.parameters}\n",
    "\n",
    "\n",
    "       #calculate the new sim with new self .parameters \n",
    "        sim_data = battery_simulation(self.ILoss,  self.U0,  self.Ri, self.CStor , SoC0= self.SoC0 , I0= self.I0, U_0= self.U_0, P= self.P)        \n",
    "    \n",
    "        def get_sim_state_new(current):\n",
    "            row = sim_data[current]\n",
    "            state = torch.tensor(row, dtype=torch.float32)\n",
    "            return state\n",
    "        \n",
    "        def get_raw_state(current):\n",
    "            sample_array = self.observation_space.sample()\n",
    "            sample_array[:] = DataFrame\n",
    "            row = sample_array[current]\n",
    "            state = torch.tensor(row, dtype=torch.float32)\n",
    "            return state\n",
    "        \n",
    "\n",
    "        self.sim_state= get_sim_state_new(self.current)\n",
    "        self.raw_state= get_raw_state(self.current)\n",
    "\n",
    "                \n",
    "        self.length-=1\n",
    "        \n",
    "        #calculate the reward for a given action   \n",
    "        #ERROR = np.mean((np.array([self.state[1], self.state[2], self.state[3]]) - np.array([self.sim_state[4], self.sim_state[5],self.sim_state[6]]))**2)\n",
    "        weight_SoC = 1\n",
    "        weight_I = 1\n",
    "        weight_U = 1\n",
    "        best_loss = float('inf')\n",
    "        gamma= 10\n",
    "\n",
    "\n",
    "        score_SoC = abs(self.state[1]- self.sim_state[0])\n",
    "        score_U = abs(self.state[2]- self.sim_state[1])\n",
    "        score_I = abs(self.state[3]- self.sim_state[2])\n",
    "        \n",
    "        ERROR =  weight_SoC*score_SoC + weight_U *score_U + weight_I*score_I \n",
    "                \n",
    " \n",
    "        val_loss = self.Error\n",
    "        \n",
    "        if ERROR < best_loss:\n",
    "             best_loss = ERROR\n",
    "        \n",
    "        reward = gamma* (best_loss - val_loss)        \n",
    "    \n",
    "    \n",
    "        def get_sim_state(current):\n",
    "            row = Sim_DataFrame[current]\n",
    "            state = torch.tensor(row, dtype=torch.float32)\n",
    "            return state\n",
    "                \n",
    "        self.current = random.randint(self.current,DataFrame.shape[0]-10)\n",
    "        self.raw_state= get_raw_state(self.current)\n",
    "        self.sim_state= get_sim_state(self.current)\n",
    "        self.Error=  abs(self.raw_state[1]- self.sim_state[0])+ abs(self.raw_state[2]- self.sim_state[1]) + abs(self.raw_state[3]- self.sim_state[2])\n",
    "        \n",
    "        self.parameters= torch.tensor([self.ILoss,  self.U0,  self.Ri, self.CStor, self.Error], dtype=torch.float32)\n",
    "\n",
    "\n",
    "        self.state= torch.cat((self.raw_state, self.sim_state, self.parameters ),0)\n",
    "        \n",
    "        if self.length <= 0 : \n",
    "            done = True \n",
    "            \n",
    "        else: \n",
    "            done= False \n",
    "            \n",
    "            \n",
    "        return  self.state, reward , done , info \n",
    "    \n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "    \n",
    "     \n",
    "    def reset(self): \n",
    "        self.ILoss= 10 #A\n",
    "        self.U0 = 1.375 #V\n",
    "        self.Ri= 0.00075  #m ohm\n",
    "        self.CStor= 8700000 #As\n",
    "        self.current=1\n",
    "        self.length=60\n",
    "        \n",
    "        \n",
    "        def get_raw_state(current):\n",
    "            sample_array = self.observation_space.sample()\n",
    "            sample_array[:] = DataFrame\n",
    "            row = sample_array[current]\n",
    "            state = torch.tensor(row, dtype=torch.float32)\n",
    "            return state\n",
    "           \n",
    "        def get_sim_state(current):\n",
    "            row = Sim_DataFrame[current]\n",
    "            state = torch.tensor(row, dtype=torch.float32)\n",
    "            return state\n",
    "        \n",
    "        self.raw_state = get_raw_state(self.current)\n",
    "        self.sim_state = get_sim_state(self.current)\n",
    "        self.Error=  abs(self.raw_state[1]- self.sim_state[0])+ abs(self.raw_state[2]- self.sim_state[1]) + abs(self.raw_state[3]- self.sim_state[2])\n",
    "        self.parameters= torch.tensor([self.ILoss,  self.U0,  self.Ri, self.CStor, self.Error], dtype=torch.float32)\n",
    "\n",
    "        self.state= torch.cat((self.raw_state, self.sim_state, self.parameters),0)\n",
    "\n",
    "\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb12dcaa-e337-473a-ab90-a7ae5379cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BatteryEnv()\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b15171a-db4c-4eb4-8538-557a60cd8a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7501e+05, 8.0000e+01, 5.7100e+01, 4.8500e+01, 7.9999e+01, 5.4770e+01,\n",
       "        4.8500e+01, 1.0000e+01, 1.3750e+00, 7.5000e-04, 8.7000e+06, 2.3307e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c43e755-0bdc-4432-80dc-8c5a7a117abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5285e+05, 2.3800e+01, 5.0800e+01, 5.5200e+01, 2.9519e+01, 5.2761e+01,\n",
       "         4.9005e+01, 1.0005e+01, 1.3800e+00, 5.7500e-03, 8.7000e+06, 1.3875e+01]),\n",
       " tensor(719.4923),\n",
       " False,\n",
       " {tensor([1.0005e+01, 1.3800e+00, 5.7500e-03, 8.7000e+06, 2.3307e+00])})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196c630c-929c-4128-b2a6-b838f0ac962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5650e+05, 2.1500e+01, 5.0400e+01, 5.5000e+01, 2.7146e+01, 5.2657e+01,\n",
       "         4.9029e+01, 1.3005e+01, 4.3800e+00, 3.0057e+00, 8.7001e+06, 1.3874e+01]),\n",
       " tensor(57678.8516),\n",
       " False,\n",
       " {tensor([1.3005e+01, 4.3800e+00, 3.0057e+00, 8.7001e+06, 1.3875e+01])})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d10b3cb8-5205-4884-91ca-5898e494250d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5749e+05, 2.0800e+01, 5.0200e+01, 5.5700e+01, 2.6506e+01, 5.2628e+01,\n",
       "         4.9035e+01, 1.3005e+01, 4.3800e+00, 3.0057e+00, 8.7001e+06, 1.4799e+01]),\n",
       " tensor(57679.6172),\n",
       " False,\n",
       " {tensor([1.3005e+01, 4.3800e+00, 3.0057e+00, 8.7001e+06, 1.3874e+01])})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57556bbe-0e47-479e-995e-70bac07b7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(): \n",
    "    \n",
    "    def __init__(self, max_size, input_shape, n_actions): \n",
    "        \n",
    "            self.mem_size = max_size \n",
    "            self.mem_cntr =0 \n",
    "\n",
    "            self.state_memory= np.zeros ((self.mem_size, *input_shape), dtype= np.float32)\n",
    "\n",
    "            self.new_state_memory= np.zeros ((self.mem_size, *input_shape),\n",
    "                                               dtype = np.float32)\n",
    "\n",
    "            self.action_memory = np.zeros(self.mem_size, dtype =np.int32)\n",
    "            self.reward_memory = np.zeros(self.mem_size, dtype =np.float32)\n",
    "            self.terminal_memory = np.zeros(self.mem_size, dtype = np.bool_)\n",
    "            \n",
    "            \n",
    "    def store_transition(self, state, action, rewrad, state_, done): \n",
    "        \n",
    "        index = self.mem_cntr % self.mem_size \n",
    "        self.state_memory[index]= state\n",
    "        self.new_state_memory[index]= state_\n",
    "        self.reward_memory[index]= reward \n",
    "        self.action_memory[index]= action \n",
    "        self.terminal_memory[index]= done\n",
    "        self.mem_cntr+=1 \n",
    "        \n",
    "    def sample_buffer(self, batch_size): \n",
    "        max_mem = min(self.mem_cntr, self.mem_size) \n",
    "        batch = np.random.choice (max_mem, batch_size, replace= False) \n",
    "        states = self.state_memory[batch]\n",
    "        actions =  self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        states_ =self.new_state_memory[batch]\n",
    "        dones =  self.terminal_memory[batch]\n",
    "        \n",
    "        return states, actions, rewards, states_, dones \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e71af1db-4e09-45e8-b6d2-434801c0803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork (nn.Module): \n",
    "    def __init__(self, lr, n_actions, name, input_dims, chkpt_dir, fc1_dims, fc2_dims): \n",
    "        \n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.checkpoint_dir = chkpt_dir \n",
    "        self.checkpoint_file= os.path.join(self.checkpoint_dir, name)\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions= n_actions\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2= nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3= nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        \n",
    "        \n",
    "        self.optimizer= optim.Adam(self.parameters(), lr=lr)\n",
    "        self.loss= nn.MSELoss()\n",
    "        self.device= T.device('cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "        \n",
    "    def forward (self, state): \n",
    "        x= F.relu(self.fc1(state))\n",
    "        x= F.relu(self.fc2(x))\n",
    "        actions= self.fc3(x) \n",
    "        \n",
    "        return actions\n",
    "    \n",
    "    def save_checkpoint(self): \n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "        \n",
    "    def load_checkpoint(self): \n",
    "        self.load_state_dict(T.load(self.checkpoint_file)) \n",
    "        \n",
    "        \n",
    "    def eval(self):\n",
    "        self.train(False)  # Set the model to evaluation mode\n",
    "   \n",
    "        super(DeepQNetwork, self).eval()  # Call the parent class's eval() function\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e948101c-acfe-4fb7-8990-fbb6d5910b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(): \n",
    "    \n",
    "    def __init__(self, gamma, epsilon, lr, input_dims, batch_size, n_actions,\n",
    "                     mem_size, eps_min= 0.01 , eps_dec= 5e-7, replace =1000, algo= None, env_name= None, chkpt_dir= 'tmp/dqn'):\n",
    "                 \n",
    "            self.gamma= gamma\n",
    "            self.epsilon= epsilon\n",
    "            self.eps_min= eps_min\n",
    "            self.eps_dec= eps_dec\n",
    "            self.lr=lr\n",
    "            self.replace_target_cnt=replace\n",
    "            self.action_space= [i for i in range (n_actions)]\n",
    "            self.batch_size= batch_size \n",
    "            self.env_name= env_name\n",
    "            self.algo= algo\n",
    "            self.chkpt_dir= chkpt_dir\n",
    "            self.mem_cntr =0 \n",
    "            self.learn_step_counter =0 \n",
    "            \n",
    "            self.memory= ReplayBuffer(mem_size, input_dims, n_actions)\n",
    "            \n",
    "            \n",
    "         \n",
    "            #Main network \n",
    "            self.Q_eval= DeepQNetwork (self.lr, n_actions=n_actions, input_dims=input_dims,\n",
    "                                       name=self.env_name+''+ self.algo+ '_Q_eval', chkpt_dir=self.chkpt_dir,\n",
    "                                       fc1_dims=256, fc2_dims=256)\n",
    "            \n",
    "            #Target Network \n",
    "            self.Q_next= DeepQNetwork (self.lr, n_actions=n_actions, input_dims=input_dims,\n",
    "                                        name=self.env_name+''+ self.algo+ '_Q_next', chkpt_dir=self.chkpt_dir,\n",
    "                                       fc1_dims=256, fc2_dims=256)\n",
    "            \n",
    "           \n",
    "\n",
    "    def store_transition (self, state, action, reward, state_, done) : \n",
    "        self.memory.store_transition(state,action,reward, state_, done)\n",
    "        \n",
    "    def choose_action(self,observation):\n",
    "        if np.random.random()>self.epsilon : \n",
    "            #state= T.tensor([observtaion], dtype= T.float).to(self.Q_eval.device)\n",
    "            state= observation.clone().detach().requires_grad_(True).to(self.Q_eval.device)\n",
    "            actions= self.Q_eval.forward(state)\n",
    "            action = T.argmax(actions).item()\n",
    "            \n",
    "        else:\n",
    "            action= np.random.choice(self.action_space)\n",
    "            \n",
    "        return action \n",
    "    \n",
    "    \n",
    "    \n",
    "    def sample_memory(self): \n",
    "        state, action, reward, new_state, done= \\\n",
    "                                  self.memory.sample_buffer(self.batch_size)\n",
    "        states= T.tensor(state).to(self.Q_eval.device)\n",
    "        rewards= T.tensor(reward).to(self.Q_eval.device)\n",
    "        dones= T.tensor(done).to(self.Q_eval.device)\n",
    "        actions= T.tensor(action ).to(self.Q_eval.device)\n",
    "        states_= T.tensor(new_state).to(self.Q_eval.device)\n",
    "        \n",
    "        return states, actions, rewards, states_, dones\n",
    "\n",
    "\n",
    "\n",
    "    def replace_target_network(self): \n",
    "        if self.learn_step_counter % self.replace_target_cnt == 0 : \n",
    "            self.Q_next.load_state_dict(self.Q_eval.state_dict())\n",
    "            \n",
    "            \n",
    "            \n",
    "    def decrement_epsilon(self): \n",
    "        self.epsilon= self.epsilon - self.eps_dec if self.epsilon > self.eps_min \\\n",
    "                               else self.eps_min        \n",
    "    \n",
    "\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr < self.batch_size: \n",
    "            return \n",
    "        \n",
    "        self.Q_eval.optimizer.zero_grad()\n",
    "        \n",
    "        self.replace_target_network()\n",
    "        \n",
    "        \n",
    "        #sample our memory\n",
    "        states, actions, rewards, states_, dones= self.sample_memory()\n",
    "        \n",
    "        indices= np.arange(self.batch_size, dtype=np.int64)\n",
    "        indices = torch.from_numpy(indices).long()\n",
    "        actions = actions.long()\n",
    "\n",
    "        \n",
    "        q_pred= self.Q_eval.forward(states)[indices, actions]\n",
    "        q_next= self.Q_next.forward (states_).max(dim=1)[0]\n",
    "        q_next[dones]= 0.0\n",
    "                               \n",
    "        q_target = rewards + self.gamma * q_next\n",
    "        \n",
    "        loss= self.Q_eval.loss(q_target, q_pred).to(self.Q_eval.device)\n",
    "        loss.backward()\n",
    "        self.Q_eval.optimizer.step()\n",
    "        self.learn_step_counter+=1\n",
    "        \n",
    "        self.decrement_epsilon()\n",
    "                               \n",
    "             \n",
    "    def save_models(self): \n",
    "        self.Q_eval.save_checkpoint()\n",
    "        self.Q_next.save_checkpoint()\n",
    "\n",
    "        \n",
    "        \n",
    "    def load_models(self): \n",
    "        self.Q_eval.load_checkpoint()\n",
    "        self.Q_next.load_checkpoint()\n",
    "\n",
    "     \n",
    "    #def eval_model(self): \n",
    "        #self.Q_eval.eval()\n",
    "        \n",
    "\n",
    "    def predict(self, obs):\n",
    "        self.Q_eval.eval()  # Set the model to evaluation mode\n",
    "        observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
    "\n",
    "        with T.no_grad():\n",
    "            predicted_action = self.Q_eval(observation_tensor)  # Pass the observation through the model\n",
    "\n",
    "        action = T.argmax(predicted_action).item() # Get the index of the predicted action\n",
    "\n",
    "        return action\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a0b9d-cd4d-45a0-919b-52747574f4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05208789-42c3-4e3f-9cdd-15586b76feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BatteryEnv()\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e03b578-7eca-4bb7-adb3-9fcd9f721558",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd516d2c-4bee-43e4-84d5-d742bca69d8d",
   "metadata": {},
   "source": [
    "# Test the agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ff3fc99-ce23-4f4d-95e0-781cd2ae9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent_with_custom_render(agent, env):\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.set_xlabel('Steps', fontweight='bold', fontsize=14)\n",
    "    ax.set_ylabel('Voltage(V)', fontweight='bold', fontsize=14)\n",
    "    sim_line, = ax.plot([], [], label='Simulated Voltage',lw= 3)\n",
    "    raw_line, = ax.plot([], [], label='Raw Voltage', color= \"#ff8888\", lw= 3)\n",
    "    ax.legend()\n",
    "    #plt.title('Voltage Testing Outcome for Charging Power cycle of 2.5 kW' , fontweight='bold', fontsize=12)\n",
    "\n",
    "    simulated_data=[]\n",
    "    raw_data=[]\n",
    "\n",
    "    #test our model \n",
    "\n",
    "    episodes = 1\n",
    "    for episode in range(1, episodes+1):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        score=0\n",
    "\n",
    "        while not done:\n",
    "            env.render()\n",
    "            obs = np.reshape(obs, [1, 12])\n",
    "            action =  agent.predict(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            score+=reward\n",
    "            \n",
    "            #transition_state= next(iter(info))\n",
    "            #simulated_data.append(transition_state[5])\n",
    "            #raw_data.append(transition_state[2])\n",
    "            \n",
    "            simulated_data.append(obs[5])\n",
    "            raw_data.append(obs[2])\n",
    "            #raw_data.append(obs[3])\n",
    "\n",
    "\n",
    "            Fscore = np.sqrt(metrics.mean_squared_error(raw_data,simulated_data))\n",
    "            MAE= mean_absolute_error(raw_data, simulated_data)\n",
    "            R_Squared= r2_score(raw_data, simulated_data, multioutput='variance_weighted')\n",
    "            \n",
    "\n",
    "        \n",
    "    print('Episode:{} Score:{} Action: {} info: {} RMSE:{}  MAE: {} R_Squared : {}'.format(episode, score, action, info, Fscore, MAE, R_Squared))\n",
    "        \n",
    "    #df_test= pd.DataFrame(list(zip(episode, score, Action, Parameters, RMSE, MAPE, R_squared)), columns=['Episode ', 'Scores', 'Action', 'Parameters', 'RMSE', 'MAPE', 'R_Squared'])\n",
    "    #df_test.to_csv('three_actions_1.pth.csv', index=False)\n",
    "    \n",
    "    sim_line.set_data(range(len(simulated_data)), simulated_data)\n",
    "    raw_line.set_data(range(len(raw_data)), raw_data)\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "    plt.show()\n",
    "    fig.savefig(filename)  \n",
    "    \n",
    "    plt.close(fig)\n",
    "    env.close()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9f3dfe5-3327-43f9-922b-4c292811f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b255895c-2245-4aee-a6a5-6e36ac3c8503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n",
      "/tmp/ipykernel_674/3801875029.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation_tensor = T.tensor(obs).clone().detach().requires_grad_(True) # Convert observation to a tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:172042.78125 Action: 1 info: {tensor([1.0300e+01, 1.6750e+00, 3.0075e-01, 8.7030e+06, 1.3124e+01])} RMSE:2.4503397941589355  MAE: 2.4380133152008057 R_Squared : -2.925064800072647\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEHCAYAAABCwJb2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0XElEQVR4nO3deVyU5f7/8dc4gAgiiqipISKGmMeFn2kuuCQq7p1KzQ3KE22YWt9MMfUcyy21zNTTImoqYWVYLrlgkqWeXHIyDcUdFTdE3IABhuX+/TExgoKOyAzM3J/n43Eej/GGmfvz0c6bi+u+7uvWKIqiIIQQQhUqlXcBQgghrEdCXwghVERCXwghVERCXwghVERCXwghVERCXwghVMShvAu4H51OV94lCCGETWrduvVdxyp86EPxhZsjISGBpk2blnE15cee+rGnXkD6qcjsqRcwv5+SBswyvSOEECpitZF+fHw84eHheHt7A+Dn50dKSgrXr18H4MaNG7Rq1Ypp06ZZqyQhhFAdq4W+Xq8nODiYSZMmFfv1iRMnMmjQIGuVI4QQqmS16Z2MjIwSv3b69GnS0tJo0aKFtcoRQghVslro6/V6dDodYWFhDB8+nD179pi+tnLlSkaMGGGtUoQQQrU01tpl89SpU5w5c4agoCASExMZOXIkW7duBeC5555jw4YNxb5Pp9Ph4uJSqnNmZWXh7Oxc6porGnvqx556AemnIrOnXsD8fvR6ffku2fT19cXX1xcAHx8fPD09SU5O5ty5c/ed1nng5VaKAnv2cOPMGar36QPu7qUtu0Kxp6Vn9tQLSD8VmT31Aja0ZDMmJoaVK1cCkJKSQmpqKnXq1OGvv/7C39+/bE92+TLs2EH1c+fg66/hHtcThBDWFx0dzeDBgwkJCWHgwIH89ttvAMyYMYOkpKRSf25ISAjHjx8v8etxcXEYDAazPuv48eOEhIQUOfbWW2+ZZigKfPPNN0yfPr3Yz4iIiGD79u0AxMbGmnVeS7Na6Pfo0YOdO3cyfPhwwsPDmTp1Kk5OTqSkpFCzZs2yPVmNGuDoaHx98ybExICZ/9BCCMs6f/48q1evJjo6mqioKD788EM+/fRTACZNmoSXl5fFzr18+XJycnJK/f5+/fqxadOmIsc2b95Mv3797vm+8+fPs3HjxlKftyxZbXrH3d2dyMjIu45PmTKl7E/m7AwDBqCsWYMGjCP/tWvhuedAqy378wkhzJaenk52djY5OTk4OjrSsGFDvvrqK8A4Up8yZQqxsbFcv36ds2fPcv78ecaOHcuaNWu4cOECkZGRXLx4kejoaBYsWADAk08+yd69e03nuHz5Mu+88w4AaWlpLFiwgD/++IM///yTl19+meXLl/Pdd9+xYcMGKlWqRPfu3fnXv/7F5cuXGTt2LG5ubvj4+NxVe+fOnZk2bRqZmZlUqVKF1NRULl++TKtWrVixYoXpB0JQUBCvvPKK6X3vv/8+hw4dYtGiRQwcONBUW25uLrNnz6ZBgwYsXryYjRs34uPjQ15eHiNGjKBZs2a8++673Lx5k7y8PCZPnvzQf/82sQ1DqTRuzOWWLal78KDxz4mJEBsLvXuDRlO+tQlRQUTuOM38bcfJMOQV89XTpfpMVyctb3b34+XOjYr9ur+/Py1atCAoKIguXbrQuXNnevbsiYND0Ti6efMmS5cu5eOPP2bt2rUsXbqU+fPnExcXd9857StXrjBq1CjatWvHwoULWbVqFRERESxYsIDIyEiSk5PZsmULX3/9NQBDhw6lV69efPXVV/Tp04cXXniBxYsXc/To0SKf6+joSKdOndi+fTt9+vQhNjaWXr16kZSUxA8//EBMTAwAgwYNolevXqb3vfTSS0RHR/PGG29w6NAhU20xMTGsWrWK1157jejoaGJjY0lPT6dnz56MGDGCFStW0KlTJwYNGsTJkyeZMWMG48ePf+B/k8LsehuGG97e0KHD7QN//QW7dpVfQUJUMJE7T5cQ+KWXYcgjcue9f2DMmTOHr776Cn9/f5YsWcLIkSO5cyFh8+bNAahVq5Yp5D09PUlPT79vDbVq1SIqKorhw4ezfv16bty4UeTrf/31F2fPniU0NJTQ0FAyMjK4cOECp06dIiAgADD+9lCcfv36sXnzZgC2bNlC//79SUhIoGXLljg4OODg4ECLFi3u+oFRXG0rVqzgxo0bnDt3jiZNmuDs7Iynp6ep9wMHDvD1118TEhLCe++9R1pa2n17vx+7Dn0AAgPh779AAH77DY4cKb96hKhAXu7UCFensp3ydHXS8nKn4kf5AIqikJ2dja+vLy+++CLfffcdycnJXLx4scj3FR75F36tKAqaO35bz83NLfLnBQsWEBgYSHR0NEOGDLmrBkdHR7p27UpUVBRRUVFs2LCBNm3aoCgKlSoZYzE/P7/Y+tu2bcvx48dJSkoiPT2dxo0bo9FoivzQKvw5dypc26hRo4rtqeC9jo6OTJkyxVRnwW8SD8N+p3cKaDQQHAzp6cYpHoD9++Hxx8u3LiEqgJc7Nyp2GsaSyxxjYmL4/fffmT17NhqNhrS0NPLz8x9oQUfVqlW5cuUKAEePHr3rjv/r16/ToEEDFEVh7969uLm5AaDRaDAYDDRr1owPP/yQzMxMnJ2dmTFjBuPGjcPHx4f4+Hj+8Y9/FLlGUJhGo6Fbt27Mnj2b3r17A8Zl5QsXLjT98Dl48CCvvvoq27ZtA4whXrBqqHBtcXFx5OfnU79+fU6cOEFOTg5paWnEx8cD0LJlS7Zt20ZAQAAnT55k586dtGvXzuy/p+LYf+iD8eJt9+5QcCFZry/feoRQsWeffZbTp08zaNAgXFxcyMnJYfLkyQ90A5W/vz8uLi4MGTKEgIAA6tevX+Trzz//PNOnT6devXp07dqVxYsXs2vXLtq2bUtISAgrV64kNDSU4cOHo9Vq6d69O87OzoSGhvLmm2/y008/4efnV+L5+/fvz7PPPsu7774LwKOPPsrzzz/PiBEjUBSFQYMGFanJ19eXo0ePMnPmzCK1FVy4Pnr0KP369WPQoEH4+vrSokULtFotI0aMYOLEiQwbNoz8/PwS9y57EFa7I7e0dDpd2eynn54O//2v8bWLC4weXUYVWo893WRiT72A9FOR2Uov33//Pf369cPBwYH+/fuzbNky6tSpc9f3PcjNWTb7EJUyUbBuH+Ah1ukKIYQlXL16lcGDB+Pk5ET//v2LDfyyoN7QVxRZuimEqDBeeeWVImv7LcX+V+8UqFQJCq8DvuNqvxBCqIF6Qh+KjvZlWwYhhAqpN/RlXl8IoUIS+kIIoSIS+kIIqzp//jwBAQGEhIQQEhLC888/z5QpU8jLe7jtINLS0ujUqdNdu2hOmDCBw4cPF/uegq0Wjh49SmLBzZt2Tl2h7+R0+7WEvhDlxsfHx7S1wLfffktOTk6JT88zl5ubGy1btjTtzQ9w6dIlMjIyaNas2T3f+9NPP3HmzJmHOr+tUFfoy0hfiAqpRYsWnD17FoBZs2YxdOhQnn32Wb777jvOnDlDWFgYAH/88QdPPPEE+fn55Obm3rWPfeHN0MC4132nTp1IS0tj1KhRhISEMHTo0CIj/2PHjvHNN98wb948Dh06xIYNGxg8eDBDhgwxbf2elpbGyJEjGTp0KMuXL6dbt24A7N+/n2HDhhEaGsqECRPMfkBLeVLPOn2Q1TtC3GnfPvjf/+76/0NTgPXrS/eZTk7QsSO0bWvWt+fk5BAXF8fQoUPJzs6mfv36TJw4kaysLLp3786uXbtITk5GURT++OMPmjZtyokTJzAYDKbdKAs89dRTzJ49G4PBgJOTE1u2bOHVV19lxYoVtGzZkldeeYW//vqLWbNmmfbwb9KkCZ06dSI4OJgWLVqQkJDAkiVLqFatGsOHD+fYsWPs27cPX19fJk+eTHR0tOl806dPZ/ny5VSvXp05c+awZcsWBgwYULq/NytRb+jLSF8I+P33sh8AGQzGz71H6CcmJpoeRXjs2DHCwsLo3r07YNxHf8iQITg6OnL9+nUA/Pz8SExM5NChQwwbNow///yTrKysu7Y/rly5Mk8++SS7du2iSZMmKIpCvXr1+O6773j99dcB45bN95q/d3d3Jzw8HIBTp05x48YNTp06ZTpXt27dWLp0KVevXuXs2bOM/ntLF71eT40aNUrzN2ZVEvpCqFmbNsWO9B+Kk5Pxc++hYE4fYMyYMaanVO3bt489e/YQFRWFo6OjaW/7Nm3acPDgQVPQz507F71eT0RExF2f3a9fP9avX8+ZM2fo27cvwF1bH5fEYDDw/vvvs27dOmrVqsWrr74KFN36uPC2x7Vr1zb1YSsk9IVQs7Ztix2RW3OTsnfeeYewsDACAwO5fv06jzzyCI6OjsTFxZGXl4fBYKBt27a8//77NG7cGA8PD65fv05GRgZ169a96/Pat2/P7NmzuXTpEh999BGpqak0b96cvXv30qpVK/78808ee+yxIu8p2HI5IyMDrVZLrVq1uHTpEvHx8eTk5NCgQQPi4+Pp1asXO3bsAIy/EQCcPHmSxo0bExUVRZs2bfD397f8X9pDkAu5Qohy5eXlRXBwMJ999hkdOnTg7NmzjBgxgqSkJLp27crUqVNp1KhRkadaVatWDW9v72I/T6vV8uSTT6LVaqlduzYAoaGhHD58mNDQUD766KO7tih+4oknmDVrFkePHqVjx44899xzLFq0iLCwMGbNmsUzzzzD/v37CQkJ4erVq2j/ftb2jBkzTFsf63Q6GjUq+eExFYXVtlaOj48nPDzc9A/l5+dHREQEERERnD17FldXVxYsWGD66VmgzLZWBuNFq+3bja9btzbusW9DbGWLWHPYUy8g/VRkZdHLhQsXOH36NJ06deLAgQMsWrSIpUuXllGFD8ZmtlbW6/UEBwcX+QkbHR1NjRo1+Oijj/j222/Zv38/QUFBlitC1ukLIUrBzc2N5cuX89+/n8lRFg8zKS9WC/07H2cGsH37dsaMGQMYn3RjcTK9I4QohWrVqpXbyL6sWW1OX6/Xo9PpCAsLY/jw4ezZs4cLFy7w+++/89JLL/HWW2/d9cT6MiehL4RQOavN6Z86dYozZ84QFBREYmIiI0eORKvV8vbbb9OnTx8+/fRT0tLSmDBhQpH36XQ6XFxcSnXOrKysIs/ddL1yhQZ79gCQ4enJuQ4dSt9QObizH1tmT72A9FOR2VMvYH4/er2+fOf0fX198fX1BYxrdD09PUlNTeWJJ54AIDAwkIULFxb73tJehLnrgoebG/wd+q5OTjZ3oUourlVc0k/FZU+9wINdyC2O1aZ3YmJiWLlyJQApKSmkpqby3HPPsXPnTgAOHz5sukHDYuRCrhBC5aw20u/Rowfjxo0jNjYWg8HA1KlTadu2LZMmTWLt2rU4OTkxe/ZsyxYhc/pCCJWzWui7u7sTGRl51/F58+ZZqwQJfSGE6skduUIIoSLqDX2DAayzcEkIISoMdYV+pUrw954ZAOTmll8tQghRDtQV+iBTPEIIVZPQF0IIFVF36MsjE4UQKqO+0JcbtIQQKqa+0JfpHSGEiknoCyGEikjoCyGEikjoCyGEiqgv9OVCrhBCxdQX+jLSF0KomLpDX9bpCyFURt2hLyN9IYTKSOgLIYSKSOgLIYSKSOgLIYSKqDv05UKuEEJl1Bf6sk5fCKFiVnswenx8POHh4Xh7ewPg5+cHwIEDB3B1dQXgpZdeomvXrpYtRKZ3hBAqZrXQ1+v1BAcHM2nSJNOxiRMnMmPGDJo2bWqtMiT0hRCqZrXpnYyMDLOOWZyEvhBCxaw60tfpdISFhZGZmcno0aPJyMhg0aJF3Lp1izp16jB58mSqV69u2UJkTl8IoWIaRVEUa5zo1KlTnDlzhqCgIBITExk5ciTjx4+nadOm+Pj48Nlnn3H16lWmTJlS5H06nQ4XF5dSnTMrKwtnZ+eiB/PzafrjjwAowNH+/UGjKdXnW1ux/dgoe+oFpJ+KzJ56AfP70ev1tG7d+q7jVhvp+/r64uvrC4CPjw+enp40b94cLy8vAHr06MHUqVOLfW9p5/wTEhKKf+/mzZCXhwZo6ucHDlb7a3goJfZjg+ypF5B+KjJ76gXM70en0xV73Gpz+jExMaxcuRKAlJQUUlNTef/997l48SIAe/fu5bHHHrNOMbJWXwihUlYb4vbo0YNx48YRGxuLwWBg6tSpaLVaRo8ejYuLC1WqVGHWrFnWKcbREbKyjK9lXl8IoSJWC313d3ciIyPvOh4YGGitEm6TFTxCCJVS3x25IKEvhFAtuw3989f1nEjNJj+/mMVJEvpCCJWyjWUrD+jyzSyCP95BhiGP5Ycy+OC5FvjVcbv9DRL6QgiVssuR/rUMAxmGPAD+OHeDvgt28vFPx8nONR6T1TtCCLWyy9B/vF41Jvb2x+Hv7nLyFD6JO0G/BbvQnb0md+UKIVTLLkMf4NUuvizq9ygBDaqbjp24ks7Az3dz7FrW7W+U0BdCqIjdhj6Adw0nYl7rwHsDmuHqpAVAUeDPS4U2epPQF0KoiFkXco8fP86hQ4dISkri1q1bAFSrVo0GDRrQvHlz0974FZG2koYXOjSka5NadJn7CwDJmflQsHWFhL4QQkVKDP3c3Fy++eYbVq1aRWJiIgB37s2m+XujMh8fH4YOHcrQoUNxqKD72HjXdMXD1YlrGQbS8gttsCYXcoUQKlJiQvft25ezZ8/i4OBAYGAgLVu2xMfHh2rVqqEoCmlpaSQmJnLw4EF2797NjBkz+Oqrr4iNjbVm/Q/Ey8OFaxkGMpVCoS8jfSGEipQY+levXuWtt95i0KBBeHh43PNDrl+/zjfffMPSpUvLvMCy1MDDhYNJN9AXvpQhoS+EUJESL+T+9NNP+Pr64ubmVtK3mNSoUYPXX3+drVu3lmlxZa2BRxUA9IqEvhBCnUoc6Xt4ePDGG2/g7u5OcHAw/fr1o23btvf8sPv9RlDeGngYH8aSKaEvhFCpey7ZbNOmDRkZGaxevZoXXniBrl27MnfuXI4ePWqt+sqU19+hL9M7Qgi1uudSm6ioKG7dusUvv/xCXFwcu3btYunSpSxbtgxfX18GDBhA3759qV+/vrXqfSgFI32Z3hFCqNV911dWq1aNAQMGMGDAAHJyctizZw+//PILO3fu5OOPP2b+/PkcOXLEGrU+tLruVXCopJHpHSGEaj3QHbmOjo54e3vj5eWFl5cXDg4Od63dr8i0lTTUr1FFRvpCCNUy606qQ4cOERcXR1xcHKdOnQLAxcWFvn370r9/f4sWWNYaeLhw8Fra7QNyc5YQQkXuGfr//ve/2b59O1evXkVRFBwcHOjSpQsDBgwgKCiIypUrW6vOMuPl4cKeO2/OUhTQaEp+kxBC2Il7hv7q1avRaDQEBATQv39/evfuTfXq1a1UmmU08HAhh0oYFA1OGsUY+Hl5UEG3jxBCiLJUYtLl5OTw5ptv0r9/f7NX5+Tk5OBY+AElhcTHxxMeHo63tzcAfn5+TJkyBYCdO3cSFhbGsWPHHrT+B3Z7rf7foW8sXEJfCKEKJV7I7dWrF15eXjzyyCP3/ZC8vDx+/PFHevfuXeL36PV6goODiYqKIioqyhT42dnZLF68mFq1apWi/AfXQNbqCyFUrMTh7c2bNxk3bhyzZs2iZ8+eBAQE0LBhQ9zc3NBoNKYN1/78809iY2NJTU2955YNGRkZxR7//PPPGTZsGHPnzn34bszgVdxafbmYK4RQiRJDf9u2bXz66af88MMPrFq1iq+//rrY71MUBTc3N0JCQnj99ddLPJFer0en0xEWFkZmZiajR4+mTp06HD16lLFjx1ot9N2rOOJexVHW6gshVEmj3GehfXZ2Nrt27eLgwYOcO3eOtDTjckc3NzcaNGhAy5YtCQwMvO9KnlOnTnHmzBmCgoJITExk5MiRNG7cmH//+980aNCAbt268fPPP9/1Pp1Oh4uLS6may8rKwtnZ+a7jY348z4zso7R11ANwtkMH9J6epTqHNZXUjy2yp15A+qnI7KkXML8fvV5P69at7zp+39C3lJ49e5KUlETz5s0BOHLkCK1ateKrr74q8n06na7Yws2RkJBA06ZN7zo+KvoPBifupotjuvHAwIHg61uqc1hTSf3YInvqBaSfisyeegHz+ykpO81esrJp0ya+/vprEhMTmTNnDrVr12bt2rX83//9H5Uq3f/G3piYGPR6PaGhoaSkpJCTk8PBgwdxcnICoFu3bncFvqV4ebigPy3TO0II9TEr9D///HPmz5+Pi4sLmZmZ5Ofnc/nyZZYsWYKDgwNvvvnmfT+jR48ejBs3jtjYWAwGA1OnTjUFvrU18HCRrRiEEKpkVuhHR0fTu3dvIiIi6NKlCwAdO3akT58+rF+/3qzQd3d3JzIyssSvFzefbykNPFw4I0s2hRAqZNaGaxkZGbRq1QqtVms6ptFoaNKkCTdu3LBUbRZjHOnLc3KFEOpj1kjfz8+PFStWmObuDx06xIkTJ1i6dCmPPfaYRQu0hLrVncnk9g+w3Kxs8y9uCCGEDTMr68aMGcOrr77KzJkzAVi4cKFpA7Z33nnHogVagqO2Eo7Ot68npKXpqVGO9QghhLWYFfodOnTg+++/Z/Xq1Zw5cwZnZ2caNGjA008/jZ+fn6VrtIgqrs7w903C+owsCX0hhCqYPavx2GOPMWnSJEvWYlWurlVMoZ+lzyrfYoQQwkrMCv3Q0NCSP8DBgfr169OvXz+efPLJMivM0qpVc4Erxtc5mdnlW4wQQliJWaG/b98+NBrNPR+NGBMTw/z58wkODi6z4iyphrur6XVetmy4JoRQB7OWbH755Zd4e3szY8YM1q1bx9q1a5kxYwYNGzbkk08+YenSpTRq1IjPP//c0vWWmZo1boe+LNkUQqiFWSP9Dz74gMGDB/Pcc8+Zjvn7+3Pz5k2++OILvv/+ewYPHsz8+fMtVWeZq+1xexvoSrk5KIqCRh6ZKISwc2aN9BMTE9mzZw+GQvvOGwwG9uzZw8mTJ8nLy2Pv3r02tZOdm1sV0+vK5JOaIVM8Qgj7Z9ZI///9v//Hjh07aN++Pd7e3mg0Gs6ePUtGRgYtW7bkr7/+4ueff6Zv376WrrfMaArt++OiyefcNT2eVW3vQe9CCPEgzBrpz5s3j8DAQPR6PUeOHOHw4cOkp6fTpk0bPvnkE+rWrUunTp1sa0lnoWf5upBP0jV9ORYjhBDWYdZI38PDgyVLlnDjxg0uXrxIfn4+devWpVKlSqSnp+Pl5XXPzdQqpEKhX0WTz7lUCX0hhP0za6RfWPXq1fHw8CArK4tPP/2UgQMHWqIuy9Nqycd44dZRAxdS08u5ICGEsDyzRvonTpzgrbfe4tSpU0WOK4pC7dq1LVKYxWk05Ds6UinHeAH3SmpaORckhBCWZ9ZI//333+fMmTM8/vjjKIpC48aNcXd35/HHH2f58uUWLtGCCk3xXLuRUY6FCCGEdZgV+vHx8YwdO5YvvvgCgAkTJvDrr79So0YNYmNjLVqgJWkrF95pM5Pz12VeXwhh38wKfVdXV86ePWu6een8+fNUrlyZ9u3bs2LFCosWaEmaOy7mbjh4qRyrEUIIyzMr9Dt16sSaNWu4cOECdevWZdasWTz33HMsXLiwyNO0bE7hZZuafNYfvFiOxQghhOWZFfoRERH06dMHJycn3nnnHfLz8zl8+DB5eXmMHj3a0jVazh1r9RMu3eLkFbmgK4SwX2at3snIyGDatGm4uLjg7+9PYGAgZ8+epWbNmmRnm7ctcXx8POHh4Xh7ewPGRzD269ePOXPm4ODggJOTE3PnzsXDw6P03TyoQnflVtHkA7D+4CX+r4dbSe8QQgibZtZIPygoiM2bN5v+XK1aNZo3b87mzZsJCQkx60R6vZ7g4GCioqKIiopiypQpfPnll8yZM4eoqCgCAgJYvXp16boorTumdwA2HLx4zy2khRDClt1zpF/w8BRFUViyZAnr1q0zfa1gisfcgMzIuHtJ5IIFC0yfn5ycTOvWrc0uvEwUCv3qjhowQOLVDOIv3KL5o+7WrUUIIazgnqHv4+PDzp070Wg0JCYmkpiYeNf33OupWoXp9Xp0Oh1hYWFkZmYyevRo2rVrx44dO5gxYwaNGjViwIABpeuitAqFfqs6LnDa+Hr9wQsS+kIIu6RRzBiq+/v78/bbb9OnT58ix6tVq4abm3nz36dOneLMmTMEBQWRmJjIyJEj2bp1K05OTiiKwocffoibmxuvvfZakffpdDpcXFweoKXbsrKy7rnds+fRo9Q6fhyAg4/48HSC8cEqni5aVgxsQKUKtr/+/fqxJfbUC0g/FZk99QLm96PX64udPTHrQm5cXBweHh5UqVLl/t9cAl9fX3x9fQHjbxCenp6sWrWKF198EY1GQ3BwMAsXLiz2vU2bNi3VORMSEu793ps34e/Q/8ejNalxNo/r+hyu6vNId67Dk41qluq8lnLffmyIPfUC0k9FZk+9gPn96HS6Yo+XGPrmTttoNBqzbtCKiYlBr9cTGhpKSkoKqampfPvttzz55JM0bdqUgwcP4uPjY9Y5y0yh1Tva3Fz6NK9H9N5zAKw/eLHChb4QQjysEkN/3759Zn2AuY8Y7NGjB+PGjSM2NhaDwcDUqVPx8PDgvffeQ6vV4uzszJw5c8yruqwUmtMnJ4cBLW+H/qa/LjF1QDMctQ+8EakQQlRYJYZ+XFxcmZ7I3d292D33v/nmmzI9zwO5I/TbNPSgrrszl25mcV2fw66TV3mqiY3uIiqEEMUoMfTr169/17GkpCROnjyJRqOhcePGPProoxYtzuLuCP1KlTT0a1GXyJ3GVUob/rwooS+EsCtmXchNT08nIiKiyOhfo9EwYMAApk+fjoODWR9T8dwR+gADWtY3hf7m+Mv8MyCFzn61yqM6IYQoc2ZNWM+ZM4dt27ZRr149goKC6Nq1K7Vq1WLdunX897//tXSNllNM6P+jfjUa164KQGZOHi98uY8PY4+Rm5dfHhUKIUSZMiv04+Li6NGjB9u2bWPRokV89tln/Pzzz3Ts2JE1a9ZYukbLKSb0NRoN8wa3pJZbZQAUBRZtP8mwyL1cvplVHlUKIUSZMSv0b968SevWrYus1NFqtQQGBnL9+nWLFWdxhZZsYjCYXrZ4tDqbxnQisLGn6di+M9fos2Any/+XyI+HLvLLsSvozl7j6OVbJN/Kkt8EhBA2wazJ+EcffZQ1a9YQFBSEl5cXAOfOnWPNmjXUq1fPogVaVDEj/QK13Cqz4l9t+XT7ST7edpx8Ba5lGJi64UixH6XRQE1XJzyrVqZ2NWc8XBxxdtTi7KilsmMlnB20ODlUouDnpgZNkfea48qVG9S+UvQ5xRXrnmHzFdeLLZN+Ki5b7cXFSUvv5nXxrFq5TD/3nqF/7do1PDw8eO2114iIiKBnz55Uq1YNgFu3bgEwa9asMi3Iqu4MfUUpksDaShpGBz1GGx8Pxnx9gCtpJW8jrShwNd3A1XQDRy9bck/+axb8bGuzp15A+qnIbLOXr/clsXFMoNn3Q5njnqHfuXNnOnbsSL9+/ZgyZQrLli3jwoULANSrV4/w8HD++c9/llkxVufgYAz+nBzIz4fsbChmT4t2jWqyeWwnVu09R9J1PenZuaRlFfwvhxv6HFIzDMWcQAghSi87N6/MP/Oeoa/Vavn111/ZsWMHzs7OBAUFMWXKFJ544gmqVq1a5sWUC1dXuHHD+Dojo9jQB6hZtTKjgx4r8WNy8vJJTTeQkpZNSnoWNzNzyMrJJ9OQR1ZuHlk5+RhyjfP+CoX2uHuArftTU1OpWfP21hC2vOv/nb3YOumn4rLVXqo4ankmoH6ZjvLhPqG/b98+/ve//xEXF8evv/7Kjz/+yMaNG6levTp9+vShX79+BAQElGlBVndn6JfyPw5HbSUecXfmEXdnwDLbMtvTxlH21AtIPxWZPfVSFu4Z+pUrV6Zbt25069YNgAMHDvDzzz/zyy+/EB0dzapVq6hfvz7btm2zSrEW4ep6+3V6evnVIYQQVvBAt9IGBAQQEBBAr169iImJISYmxjTHb7MKT1MV83QvIYSwJ2aFfm5uLnv37iUuLo6ff/6Z5ORkFEWhXr169O/f39I1Wlbhkb6EvhDCzt0z9Ddu3EhcXBw7duwgIyMDRVGoXr06zz//PP3797f+M20tQUJfCKEi9wz9t99+GwBnZ2d69epF//796dy5s+1usFYcCX0hhIrcM707dOjAgAED6NGjB66Fw9GeSOgLIVTknqG/bNkya9VRfiT0hRAqIs8CdHG5/VqvN96ZK4QQdkpC38Hh9l24igKZmeVbjxBCWJCEPsgUjxBCNST0oegNWnJXrhDCjllt7WV8fDzh4eF4e3sD4OfnR1hYGBMnTiQ3NxcHBwfmzp1LrVrl8DxaGekLIVTCaqGv1+sJDg5m0qRJpmMTJkxg8ODB9OnTh+joaL788kvGjx9vrZJuk9AXQqiE1UI/o5gw/c9//kPlysanwtSoUYPDhw9bq5yiJPSFECqhURTFKtuyb9y4kaVLl+Lh4UFmZiajR4+mXbt2AOTl5fHCCy8watQo2rdvX+R9Op0Ol8LLKh9AVlYWziXsj19YtaQk6h84AMDN+vW5WEG3lzC3H1tgT72A9FOR2VMvYH4/er2+2K1yrDbS9/f3Z9SoUQQFBZGYmMjIkSPZunUrWq2W8ePH065du7sCv0Bp98I2ex9tZ2f4O/TdtVrcK+je2/a0L7g99QLST0VmT72A+f3odLpij1st9H19ffH19QXAx8cHT09PkpOTWbhwId7e3rzxxhvWKuVusr2yEEIlrLZkMyYmhpUrVwKQkpJCamoq+/fvx9HRkTFjxlirjOLJnL4QQiWsNtLv0aMH48aNIzY2FoPBwNSpU/nss8/Izs4mJCQEMP42MHXqVGuVdFuVKqDRGO/IzcqC3FzjnbpCCGFnrJZs7u7uREZGFjnWpUsXa53+3jQa42i/4MYsvR6qVSvfmoQQwgLkjtwC8qxcIYQKSOgXkHl9IYQKSOgXkNAXQqiAhH4BCX0hhApI6BeQ0BdCqICEfgEJfSGECkjoF5C7coUQKiChX0BG+kIIFZDQL3Bn6Ftn81EhhLAqCf0CTk63t17IyQGDoXzrEUIIC5DQL1CwFUMBmeIRQtghCf3CJPSFEHZOQr8wCX0hhJ2T0C9MQl8IYeck9AuT0BdC2DkJ/cIK36Al2ysLIeyQhH5hhUf6en351SGEEBYioV+YTO8IIeychH5h8vQsIYSdk9Av7M7pHdmKQQhhZ6wW+vHx8XTu3JmQkBBCQkKYNm0aAFFRUTRr1oyMijCd4uAAlSsbX+fnQ2Zm+dYjhBBlzMFaJ9Lr9QQHBzNp0iTTsbVr13L16lVq165trTLuz9UVsrONrzMywMWlfOsRQogyZLWRfnEj+e7du/PWW2+h0WisVcb9yb76Qgg7ZtWRvk6nIywsjMzMTEaPHk27du3Mem9CQkKpzpmVlfXA762Xm4v7368vHD/OrQo0xVOafioqe+oFpJ+KzJ56gYfvx2qh7+/vz6hRowgKCiIxMZGRI0eydetWnJyc7vvepk2bluqcCQkJD/7eCxfg4kUA6ru7U7+U57aEUvVTQdlTLyD9VGT21AuY349Opyv2uNVC39fXF19fXwB8fHzw9PQkOTkZLy8va5VgHpneEULYMavN6cfExLBy5UoAUlJSSE1NpU6dOtY6vfnkrlwhhB2z2ki/R48ejBs3jtjYWAwGA1OnTmXp0qX89ttvpKSk8PLLL9OqVSvGjx9vrZKKJzdoCSHsmNVC393dncjIyCLHunTpwuuvv26tEswjWzEIIeyY3JF7Jwl9IYQdk9C/k4uL8Xm5YLwjNy+vfOsRQogyJKF/p0qVit6FK/P6Qgg7IqFfnJo1b78+ebL86hBCiDImoV8cf//br48cKb86hBCijEnoF6dJE+M0Dxjvzr1+vXzrEUKIMiKhXxwXF/Dxuf1nGe0LIeyEhH5JHn/89usjR+SBKkIIuyChX5LHHgNHR+Pra9cgObl86xFCiDIgoV8SR0fw87v958OHy68WIYQoIxL691J4iufoUeMjFIUQwoZJ6N9Lw4a3b9RKT4dz58q1HCGEeFgS+vdSqRIUfliBrOIRQtg4Cf37KTzFc+wY5OaWXy1CCPGQJPTvp25dqF7d+NpgkG0ZhBA2TUL/fjSau9fsCyGEjbLaQ1RsWrNm8NtvxtcnTsDs2UW/7uEBHTsa5/8LtmUWQogKSEb65vDwgEceKfnr167Bhg3w1Vdw4YL16hJCiAckI31zde1qDPZ7PU3r4kVj8Pv7G0f+hfflLwPa7Gy7eVi7PfUC0k9FZrO9aLVQuXKZf6xGUSr2pjI6nY7WrVuX6r0JCQk0Lbzk8mEV91eVnQ179sD+/fKULSFE2dFooE0beOqpIofNzbWSstNqI/34+HjCw8Px9vYGwM/Pj7CwMMaPH09eXh61atVi7ty5ODk5WaukB1fcfL2zs/G3gFat4NdfjXfuCiHEw1IUOHTImC9leK3QaqGv1+sJDg5m0qRJpmMTJ05k2LBh9O7dmzlz5hATE8OwYcOsVVLZql4dnn4aWreGXbvgypUyP0VuXh4OWm2Zf255sKdeQPqpyGy2F0dHaNeuzBeHWC30M4qZC9+7dy/vvfceAEFBQSxfvtx2Q7/Ao4/CkCEW+egTZT1dVY7sqReQfioye+qlLFh1pK/T6QgLCyMzM5PRo0eTmZlpms6pVasWKSkpxb43ISGhVOfMysoq9XsrInvqx556AemnIrOnXuDh+7Fa6Pv7+zNq1CiCgoJITExk5MiR5Bba0uBe15NL+1O6zC/kljN76seeegHppyKzp17gwS7kFsdqoe/r64uvry8APj4+eHp6cunSJbKysnB2diY5OZnatWtbqxwhhFAlq92cFRMTw8qVKwFISUkhNTWVZ599ltjYWAC2bt1Kp06drFWOEEKoktVG+j169GDcuHHExsZiMBiYOnUqTZs2ZcKECXz77bfUq1ePf/7zn9YqRwghVMlqoe/u7k5kZORdx7/88ktrlSCEEKone+8IIYSK2MQ2DEIIIR5ccdswVPjQF0IIUXZkekcIIVREQl8IIVTEbvfTnzlzJgcPHkSj0fDuu+/SokWL8i7pgR0/fpzw8HBefPFFRowYwaVLl2xrV9JC5syZg06nIzc3l1dffZXmzZvbbC+ZmZlERESQmppKdnY24eHh+Pv722w/YLy1v2/fvowaNYr27dvbbC92sZvvHdavX8+SJUtwcHBg7Nix+Pn5PVw/ih3au3ev8sorryiKoignTpxQBg4cWM4VPbiMjAxlxIgRyuTJk5WoqChFURQlIiJC2bRpk6IoijJ79mwlOjq6PEs02+7du5WwsDBFURTl2rVrSpcuXWy2F0VRlI0bNyqLFy9WFEVRzp8/r/Ts2dOm+1EURZk3b57y7LPPKmvWrLHpXvbu3atMnz69yDFb7ufatWtKz549lbS0NCU5OVmZPHnyQ/djl9M7u3fvpnv37gA0btyYW7dukZ6eXs5VPRgnJyciIyOLbE2xd+9egoKCAOOupLt37y6v8h5ImzZt+OSTTwDj/RqZmZk22wtAnz59ePnllwG4dOkSderUsel+Tp06xcmTJ+natStgu/+dQcm7+dpqP7t376Z9+/ZUrVqV2rVrM23atIfuxy5D/+rVq9SoUcP055o1a5a4g2dF5eDggLOzc5Fj5u5KWtFotVpc/n505HfffUfnzp1ttpfChgwZwrhx43j33Xdtup/Zs2cTERFh+rMt91J4N9/hw4ezZ88em+7n/PnzKIrCm2++ybBhw9i9e/dD92OXc/rKHatQFUVBU8YPIigPhXu4s0dbsG3bNmJiYli2bBnBwcGm47bYC8A333xDQkIC77zzjs3+26xdu5ZWrVrh5eVlOmarvcDD7eZbUSUnJ7No0SIuXrxIaGjoQ//72GXo16lTh6tXr5r+fOXKFTw9PcuxorJRpUoVm92VdOfOnXz++ecsWbIENzc3m+4lPj6emjVrUrduXZo2bUpeXp7N9vPLL7+QlJTEL7/8wuXLl3FycrLZXsD+dvOtWbMmAQEBODg40KBBA1xdXdFqtQ/Vj11O73Ts2NG0e+eRI0eoXbs2VatWLeeqHl6HDh1sclfStLQ05syZwxdffEH16tUB2+0FYP/+/SxbtgwwTiXq9Xqb7Wf+/PmsWbOG1atXM2jQIMLDw222F7C/3XwDAwPZs2cP+fn5XLt2rUz+W7PbO3I//PBD9u/fj0aj4T//+Q/+/v7lXdIDiY+PZ/bs2Vy4cAEHBwfq1KnDhx9+SEREBNnZ2dSrV49Zs2bh6OhY3qXe17fffsvChQvx8fExHfvggw+YPHmyzfUCxuWNkyZNMo0g33jjDf7xj38wYcIEm+ynwMKFC6lfvz6BgYE228vNmzcZN24cer0eg8HAG2+8YdrN1xb7AeM04saNG8nMzOT111+nefPmD9WP3Ya+EEKIu9nl9I4QQojiSegLIYSKSOgLIYSKSOgLIYSKSOgLIYSKSOgLIYSKSOgLVbp58yYzZ84kKCiI5s2b06pVK4YMGcKWLVsAyMnJoXXr1nz//fflXKkQZcsut2EQ4n7Cw8PZv38/vXv35oknnuDKlSusXLmSN998ky+//BLA5nZmFcIccnOWUJ2rV6/SsWNHXF1d+eOPP0zHN27cyIEDBzh27Bj79u0zHW/bti1RUVEkJSUxc+ZMDhw4QE5ODt27d2fKlClUrVqV3bt38+KLLzJ06FCqVKnCmjVr0Gg0jB49mhEjRgCQmprKzJkz2b17NxkZGfj6+jJmzBjTlsZCWINM7wjVcXNzw9HRkYyMDGbPns3p06cB6Nu3L5MnTyYiIoKnnnoKgGeffZaXXnoJg8HAyJEj2bVrF8OGDWPo0KGsX7+eOXPmAFCpkvH/Sps2beLChQu89NJL5OTkMG3aNHQ6HQDTpk1j8+bNDBo0iHfeeYfc3FxGjRrFuXPnyuFvQaiVTO8I1alcuTJjxoxh3rx5LFu2jGXLluHh4UG7du0YPHgw7du3p1mzZmzfvp02bdrQtWtXtm3bRlJSEr1792bo0KGAcX+kdevWFdmLvmrVqnz88cdotVoA5s2bx8aNG2ndujWJiYlUrlyZZ555hoYNGxIUFMSlS5fw8PAol78HoU4S+kKVXnnlFbp27cqmTZv4/fff+euvv9i0aRObNm1i5syZd31/wW8DmzdvZvPmzUW+dvHiRdPrli1bmgK/YJO/pKQkAJ5++mlmz55NcHAwDRs2pG3btgwZMsQudoAVtkNCX6iWn58ffn5+gPExex999BHR0dFER0ebpncKFDzFLDg4mIEDBxb5Wu3atUlNTQUo8sCO/Px84PZDSf71r3/RokULtmzZwv79+/nuu+/44YcfiI6OpmXLlpZpUog7yJy+UJ1ff/2VF154gYULF5qOubq68swzzwBFnxyVl5cHgLe3NwDZ2dl07tyZzp07U7VqVdzd3U2PggRISEgwPc3o2LFjAHh5eZGbm8uff/6Jk5MTkydPZu3atcyaNYucnBx27Nhh2YaFKERG+kJ1GjVqxJEjR9i3bx+XLl3i8ccfR6/X88MPPwDG0XzlypUBWLNmDY6OjvTp04f69evz66+/Mn36dFxdXYmMjKRZs2asXr3a9NmpqamMHz+exx9/nKVLlwLGaR2AsWPHkpmZSVhYGG5ubvz0008ANGnSxJrtC5WTJZtClU6cOMHnn3/O/v37SU1NxcHBgUaNGjFw4ECGDRvGlStXCAsL4/Tp03To0IHFixdz4cIFpk+fzh9//IFGo6FDhw5MnDiRWrVqsXfvXkJDQxkwYACurq6sW7eOKlWq8NZbbzFo0CDTOT/44AMOHjyIwWDg0UcfZdiwYaYlnUJYg4S+EGWgIPSfeeYZPvjgg/IuR4gSyZy+EEKoiIS+EEKoiEzvCCGEishIXwghVERCXwghVERCXwghVERCXwghVERCXwghVERCXwghVOT/A98o0ZkKv0+wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "env = BatteryEnv()\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "filename= 'v_cc_100.png'  \n",
    "\n",
    "agent= DQNAgent(gamma= 0.99, epsilon= 1.0, lr= 0.001, input_dims= [12],\n",
    "                                                         n_actions= 3, mem_size= 500000, eps_min=0.1, \n",
    "                                                         batch_size=64 , replace =1000, eps_dec=1e-5, chkpt_dir='models/', algo= 'dqn_3_D_r3_more', \n",
    "                                                         env_name='BatteryEnv')\n",
    "#agent.load_models()\n",
    "test_agent_with_custom_render(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cfaa188-bc69-4fb6-91d1-efc5c40b7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent_with_custom_render2(agent, env):\n",
    "  \n",
    "    simulated_data=[]\n",
    "    raw_data=[]\n",
    "\n",
    "    #test our model \n",
    "\n",
    "    episodes = 1\n",
    "    for episode in range(1, episodes+1):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        score=0\n",
    "\n",
    "        while not done:\n",
    "            env.render()\n",
    "            obs = np.reshape(obs, [1, 11])\n",
    "            action =  agent.predict(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            score+=reward\n",
    "            \n",
    "           # transition_state= next(iter(info))\n",
    "            #simulated_data.append(transition_state[5])\n",
    "            #raw_data.append(transition_state[2])\n",
    "            \n",
    "           # simulated_data.append(obs[6])\n",
    "           # raw_data.append(obs[3])\n",
    "\n",
    "           # Fscore = np.sqrt(metrics.mean_squared_error(raw_data,simulated_data))\n",
    "           # MAPE= mean_absolute_percentage_error(raw_data, simulated_data)\n",
    "           # R_Squared= r2_score(raw_data, simulated_data, multioutput='variance_weighted')\n",
    "            \n",
    "\n",
    "        \n",
    "        print('Episode:{} Score:{} State : {} Action: {} info: {}'.format(episode, score,obs,  action, info))\n",
    "        \n",
    "    #df_test= pd.DataFrame(list(zip(episode, score, Action, Parameters, RMSE, MAPE, R_squared)), columns=['Episode ', 'Scores', 'Action', 'Parameters', 'RMSE', 'MAPE', 'R_Squared'])\n",
    "    #df_test.to_csv('three_actions_1.pth.csv', index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60804853-bfdb-41de-9850-798cda74c260",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12 into shape (1,11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:58\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: reshape() got an unexpected keyword argument 'order'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m agent\u001b[38;5;241m=\u001b[39m DQNAgent(gamma\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m, lr\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m, input_dims\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      7\u001b[0m                                                          n_actions\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, mem_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500000\u001b[39m, eps_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                                          batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m , replace \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, eps_dec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, chkpt_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m'\u001b[39m, algo\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDQNAgent\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m                                                          env_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatteryEnv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#agent.load_models()\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtest_agent_with_custom_render2\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mtest_agent_with_custom_render2\u001b[0;34m(agent, env)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     15\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m---> 16\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     action \u001b[38;5;241m=\u001b[39m  agent\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[1;32m     18\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:299\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:67\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:44\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 12 into shape (1,11)"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "env = BatteryEnv()\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "agent= DQNAgent(gamma= 0.99, epsilon= 1.0, lr= 0.0001, input_dims= [11],\n",
    "                                                         n_actions= 3, mem_size= 500000, eps_min=0.1, \n",
    "                                                         batch_size=64 , replace =1000, eps_dec=1e-5, chkpt_dir='models/', algo= 'DQNAgent', \n",
    "                                                         env_name='BatteryEnv')\n",
    "#agent.load_models()\n",
    "test_agent_with_custom_render2(agent, env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
